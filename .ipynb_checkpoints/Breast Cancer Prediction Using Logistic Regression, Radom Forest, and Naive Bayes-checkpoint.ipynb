{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23887e01",
   "metadata": {},
   "source": [
    "# Import libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2347d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries and load data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv('wdbc-data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceafa342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db8a1b",
   "metadata": {},
   "source": [
    "# Assign a title to each column of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afa7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Assign a title to each column of the dataset\n",
    "column_names = ['id', 'diagnosis', 'mean_radius', 'mean_texture', 'mean_perimeter',\n",
    "                'mean_area', 'mean_smoothness', 'mean_compactness', 'mean_concavity',\n",
    "                'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "                'se_radius', 'se_texture', 'se_perimeter', 'se_area', 'se_smoothness',\n",
    "                'se_compactness', 'se_concavity', 'se_concave_points', 'se_symmetry',\n",
    "                'se_fractal_dimension', 'worst_radius', 'worst_texture', 'worst_perimeter',\n",
    "                'worst_area', 'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
    "                'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension']\n",
    "df.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b2152a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   worst_smoothness  worst_compactness  worst_concavity  worst_concave_points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst_symmetry  worst_fractal_dimension  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6119867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data preprocessing (Min-max Normalization and Feature selection using selectkbest)\n",
    "X = df.drop(['id', 'diagnosis'], axis=1)\n",
    "y = df['diagnosis'].map({'B': 0, 'M': 1})  # Convert B to 0 and M to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4654954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6fbe34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using SelectKBest with chi2 scoring function\n",
    "k_best_features = 20\n",
    "feature_selector = SelectKBest(chi2, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X_normalized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "baea02c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area',\n",
      "       'mean_compactness', 'mean_concavity', 'mean_concave_points',\n",
      "       'se_radius', 'se_perimeter', 'se_area', 'se_concave_points',\n",
      "       'worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
      "       'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
      "       'worst_concave_points', 'worst_symmetry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get the selected feature indices\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5f26f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d0797b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Training using Logistic Regression with L2 regularization to prevent overfitting\n",
    "logreg_model = LogisticRegression(penalty='l2')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8bcbdeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Training using Random Forest with max_depth parameter to prevent overfitting\n",
    "rf_model = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aee69b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Training using NaÃ¯ve Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2b00e890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9736842105263158\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        71\n",
      "           1       1.00      0.93      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Random Forest Accuracy: 0.9649122807017544\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        71\n",
      "           1       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "NaÃ¯ve Bayes Accuracy: 0.9649122807017544\n",
      "NaÃ¯ve Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        71\n",
      "           1       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Model evaluation based on prediction\n",
    "# Calculate accuracy scores and classification reports\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "classification_report_logreg = classification_report(y_test, y_pred_logreg)\n",
    "classification_report_rf = classification_report(y_test, y_pred_rf)\n",
    "classification_report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report_logreg)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report_rf)\n",
    "\n",
    "print(\"NaÃ¯ve Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"NaÃ¯ve Bayes Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cf7fecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (Logistic Regression): [0.95614035 0.96491228 0.97368421 0.95614035 0.96460177]\n",
      "Cross-Validation Scores (Random Forest): [0.92105263 0.93859649 0.98245614 0.96491228 0.96460177]\n",
      "Cross-Validation Scores (NaÃ¯ve Bayes): [0.90350877 0.9122807  0.95614035 0.94736842 0.92035398]\n",
      "Mean Cross-Validation Score (Logistic Regression): 0.9630957925787922\n",
      "Mean Cross-Validation Score (Random Forest): 0.9543238627542306\n",
      "Mean Cross-Validation Score (NaÃ¯ve Bayes): 0.927930445582984\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Apply k-fold Cross-Validation to check generalization performance\n",
    "cv_scores_logreg = cross_val_score(logreg_model, X_normalized, y, cv=5)\n",
    "cv_scores_rf = cross_val_score(rf_model, X_normalized, y, cv=5)\n",
    "cv_scores_nb = cross_val_score(nb_model, X_normalized, y, cv=5)\n",
    "\n",
    "print(\"Cross-Validation Scores (Logistic Regression):\", cv_scores_logreg)\n",
    "print(\"Cross-Validation Scores (Random Forest):\", cv_scores_rf)\n",
    "print(\"Cross-Validation Scores (NaÃ¯ve Bayes):\", cv_scores_nb)\n",
    "print(\"Mean Cross-Validation Score (Logistic Regression):\", np.mean(cv_scores_logreg))\n",
    "print(\"Mean Cross-Validation Score (Random Forest):\", np.mean(cv_scores_rf))\n",
    "print(\"Mean Cross-Validation Score (NaÃ¯ve Bayes):\", np.mean(cv_scores_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a409d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation: Add random noise to feature values\n",
    "num_augmented_samples = 1000  # Number of synthetic samples to generate\n",
    "augmented_data = []\n",
    "for _ in range(num_augmented_samples):\n",
    "    augmented_sample = X_normalized + np.random.normal(loc=0, scale=0.01, size=X_normalized.shape)\n",
    "    augmented_data.append(augmented_sample)\n",
    "\n",
    "X_augmented = np.vstack(augmented_data)\n",
    "y_augmented = np.tile(y, num_augmented_samples)\n",
    "\n",
    "# Combine original data with augmented data\n",
    "X_combined = np.vstack((X_normalized, X_augmented))\n",
    "y_combined = np.concatenate((y, y_augmented))\n",
    "\n",
    "# Step 4: Training using Logistic Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "# Step 6: Training using Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Step 7: Training using NaÃ¯ve Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "72dd67d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9866566005934301\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     71597\n",
      "           1       0.99      0.98      0.98     42317\n",
      "\n",
      "    accuracy                           0.99    113914\n",
      "   macro avg       0.99      0.98      0.99    113914\n",
      "weighted avg       0.99      0.99      0.99    113914\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71597\n",
      "           1       1.00      1.00      1.00     42317\n",
      "\n",
      "    accuracy                           1.00    113914\n",
      "   macro avg       1.00      1.00      1.00    113914\n",
      "weighted avg       1.00      1.00      1.00    113914\n",
      "\n",
      "NaÃ¯ve Bayes Accuracy: 0.938049756834103\n",
      "NaÃ¯ve Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     71597\n",
      "           1       0.93      0.90      0.92     42317\n",
      "\n",
      "    accuracy                           0.94    113914\n",
      "   macro avg       0.94      0.93      0.93    113914\n",
      "weighted avg       0.94      0.94      0.94    113914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Model evaluation based on prediction\n",
    "# Calculate accuracy scores and classification reports\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "classification_report_logreg = classification_report(y_test, y_pred_logreg)\n",
    "classification_report_rf = classification_report(y_test, y_pred_rf)\n",
    "classification_report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report_logreg)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report_rf)\n",
    "\n",
    "print(\"NaÃ¯ve Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"NaÃ¯ve Bayes Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "610c63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Step 4: Handling class imbalance using SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_combined, y_combined)\n",
    "\n",
    "# Step 5: Training using Logistic Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "# Step 6: Training using Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Step 7: Training using NaÃ¯ve Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "efef5d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9827973387993816\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     71473\n",
      "           1       0.99      0.98      0.98     71470\n",
      "\n",
      "    accuracy                           0.98    142943\n",
      "   macro avg       0.98      0.98      0.98    142943\n",
      "weighted avg       0.98      0.98      0.98    142943\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71473\n",
      "           1       1.00      1.00      1.00     71470\n",
      "\n",
      "    accuracy                           1.00    142943\n",
      "   macro avg       1.00      1.00      1.00    142943\n",
      "weighted avg       1.00      1.00      1.00    142943\n",
      "\n",
      "NaÃ¯ve Bayes Accuracy: 0.9300000699579553\n",
      "NaÃ¯ve Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     71473\n",
      "           1       0.96      0.90      0.93     71470\n",
      "\n",
      "    accuracy                           0.93    142943\n",
      "   macro avg       0.93      0.93      0.93    142943\n",
      "weighted avg       0.93      0.93      0.93    142943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Model evaluation based on prediction\n",
    "# Calculate accuracy scores and classification reports\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "classification_report_logreg = classification_report(y_test, y_pred_logreg)\n",
    "classification_report_rf = classification_report(y_test, y_pred_rf)\n",
    "classification_report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report_logreg)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report_rf)\n",
    "\n",
    "print(\"NaÃ¯ve Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"NaÃ¯ve Bayes Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b73e5729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "709    1\n",
       "710    1\n",
       "711    1\n",
       "712    1\n",
       "713    1\n",
       "Name: diagnosis, Length: 714, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e40e9183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print (y_balanced.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acfcb8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca0560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
